<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Introduction to Machine Learning</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous"><link rel="stylesheet" href="/_astro/index.CZec6rt8.css">
<style>[data-astro-image]{width:100%;height:auto;-o-object-fit:var(--fit);object-fit:var(--fit);-o-object-position:var(--pos);object-position:var(--pos);aspect-ratio:var(--w) / var(--h)}[data-astro-image=responsive]{max-width:calc(var(--w) * 1px);max-height:calc(var(--h) * 1px)}[data-astro-image=fixed]{width:calc(var(--w) * 1px);height:calc(var(--h) * 1px)}
</style></head> <body class="max-w-2xl mx-auto px-6 py-12 font-serif"> <header class="mb-16"> <a href="/posts" class="text-sm text-gray-500 hover:text-gray-700 hover:underline">← Back to notes</a> <h1 class="text-3xl font-normal mt-8 mb-2">Introduction to Machine Learning</h1> <div class="tex-sm text-gray-500"> December 27, 2024 </div> </header> <main class="prose prose-lg"> <h1 id="introduction">Introduction</h1>
<hr/>
<p>Let’s talk about machine learning. It’s a rapidly advancing field and its relevance can’t be understated. It’s provided solutions to complex problems that traditional algorithms are unable to solve by essentially teaching computers to learn how to solve these problems. It sounds very outlandish to say “teaching computers” but, with the help of math, probability theory and a boatload of statistics, computers have gotten really good at observing patterns and copying them. My goal is gain and in-depth understanding of how this has been achieved and see how I can apply this knowledge to provide creative solutions to complex problems around me. Join me as i dive headfirst into the interesting but unbelievably <em>convoluted</em> world of machine learning (pun intended).</p>
<p>I’m going to dive into two fundamental categories of machine learning:</p>
<ul>
<li>Supervised Learning</li>
<li>Unsupervised Learning</li>
</ul>
<p>While there are other types of machine learning, these two are the most relevant at this stage.</p>
<h2 id="supervised-learning">Supervised Learning</h2>
<hr/>
<p>This approach to machine learning involves giving the computer a number of examples to learn from in the form of input-output pairs. Basically an input, also called a <em>feature</em> is mapped to an output, also called <em>target</em>, and the computer observes a list of these mappings and tries to predict what the output should be for an input that isn’t a part of the original mappings.</p>
<p>For example, let’s say you plot house prices against house sizes for about 15 houses. The goal would be to get the computer to estimate the price of a house based on its size, especially for houses not represented in the dataset. This is called a <em>regression problem</em>.</p>
<p>Another application of supervised learning is breast cancer detection. A model can learn to predict whether a tumor is cancerous based on its size. When provided with a plot of patient age against tumor size, with malignant and benign tumors marked on the plot, the model might attempt to create a boundary to distinguish categories associated with malignant tumors and those that are not. This problem is categorized as a <em>classification problem</em>. Unlike regression, classification requires the model to predict an output out of a finite set of classes. In the example the model has to predict an output out of two classes but this isn’t always the case. This model could be repurposed to classify between benign, and multiple types of malignant tumors.</p>
<h2 id="unsupervised-learning">Unsupervised Learning</h2>
<hr/>
<p>With supervised learning, a model learns from data labeled with <em>correct</em> answers. In contrast, unsupervised learning involves providing the model with unlabeled data and tasking it with finding any patterns or structures hidden within the data. Let’s say we have another patient age vs tumor size plot except the points aren’t labeled. A model might try to group the points into categories or <em>clusters</em>. This is type of supervised learning algorithm called a <em>clustering algorithm</em>. Google News employs this algorithm to group related news articles. Achieving this with supervised learning is unfeasible for obvious reasons. Other unsupervised learning algorithms include <em>anomaly detection</em> and <em>dimensionality reduction</em>.</p>
<h2 id="terminology">Terminology</h2>
<hr/>
<ul>
<li><strong>Training Set</strong>: Data used to train the model.</li>
<li><strong>Input Variable (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">x</span></span></span></span>)</strong>: The input provided to the model in the training set. Also known as the <em>feature</em> or <em>input feature</em>.</li>
<li><strong>Output Variable (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span></span>)</strong>: The <em>correct</em> output provided to the model in the training set. Also know as the <em>target variable</em>.</li>
<li><strong>Training Example (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo separator="true">,</mo><msup><mi>y</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">x^{(i)}, y^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0824em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>)</strong>: This is a pair consisting of some feature and its expected target. The superscript <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal">i</span></span></span></span> represents the position of the training example in the dataset, for instance, in a table.</li>
<li><strong>Total Number of Training Examples (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">m</span></span></span></span>)</strong>: I believe this is self-explanatory.</li>
</ul>
<p>In summary, supervised and unsupervised learning are two very broad categories of machine learning. Supervised learning gives the model a blueprint and expects it to accurately produce the patterns explicity provided in the blueprint while unsupervised learning gives the model a pool of data and expects it to recognize patterns hidden in the data. In the next post I’ll write in detail about linear regression.</p> </main> </body></html>